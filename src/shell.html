<!doctype html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>C++ Audio (DSP Worker)</title>
    <style>
        body { font-family: sans-serif; text-align: center; }
        #controlButton { font-size: 1.5em; }
    </style>
  </head>
  <body>
    <h1>C++ WebAssembly Audio Engine (With a dedicated DSP Worker)</h1>
    <button id="controlButton">Start Audio</button>
    <div id="status"></div>

    <!-- This special tag is where Emscripten injects its JS loader -->
    {{{ SCRIPT }}}

    <script type='text/javascript'>
      const controlButton = document.getElementById('controlButton');
      const statusElement = document.getElementById('status');

      // This is the global "struct" to hold all our audio components.
      const audioSystem = {
        audioContext: null,
        dspWorker: null,
        isReady: false
      };

      // The `Module` object must be defined in the global scope before the
      // Emscripten script runs, so it can be found.
      var Module = {
        // We will populate this in the main logic.
        onRuntimeInitialized: null 
      };

      // This self-executing async function is our main entry point.
      (async () => {
        // Step 1: Handle the Service Worker and COOP/COEP headers.
        if (typeof SharedArrayBuffer === 'undefined') {
          statusElement.innerHTML = "SharedArrayBuffer is not available. <br> Activating headers via Service Worker and reloading...";
          controlButton.disabled = true;
          const registration = await navigator.serviceWorker.register('coop-coep-sw.js');
          // Wait for the service worker to actually take control before reloading.
          await new Promise(resolve => navigator.serviceWorker.addEventListener('controllerchange', resolve));
          console.log("Service Worker has taken control. Reloading page.");
          location.reload();
          return; // Stop execution; the page will reload.
        }

        // If we get here, SharedArrayBuffer is available. It's safe to proceed.
        statusElement.textContent = 'COOP/COEP Headers active. Waiting for WASM runtime...';

        // Step 2: Define the onRuntimeInitialized callback.
        // This function will be called by the Emscripten loader once the WASM is ready.
        Module.onRuntimeInitialized = () => {
          console.log('Emscripten runtime initialized.');

          // The C++ main() function runs to initialize the C++ side.
          Module.callMain(); 

          // Now that the C++ side is ready, enable the UI.
          controlButton.disabled = false;
          controlButton.addEventListener('click', toggleAudio);
          statusElement.textContent = 'WASM Ready. Click Start Audio to initialize audio systems.';
        };

      })();

      // This function is the main setup routine, called only once.
      async function setupAudio() {
        // Create the AudioContext.
        audioSystem.audioContext = new (window.AudioContext || window.webkitAudioContext)();
        audioSystem.dspWorker = new Worker('dsp-worker.js');
        await audioSystem.audioContext.audioWorklet.addModule('audioworklet-processor.js');

        const buffer_frames = 8192;
        const audio_sab = new SharedArrayBuffer(buffer_frames * 2 * 4);
        const state_sab = new SharedArrayBuffer(2 * 4);

        // Get the real Sample Rate
        const actual_sample_rate = audioSystem.audioContext.sampleRate;
        statusElement.textContent = `AudioContext created at ${actual_sample_rate} Hz. Initializing DSP worker...`;

        audioSystem.dspWorker.postMessage({
            type: 'init',
            wasm_module_name: 'CrossPlatformAudio.js',
            sample_rate: actual_sample_rate, // Pass the correct sample rate
            audio_sab: audio_sab,
            state_sab: state_sab
        });

        const workletNode = new AudioWorkletNode(audioSystem.audioContext, 'cpp-audio-processor');
        workletNode.port.postMessage({ audio_sab: audio_sab, state_sab: state_sab });

        workletNode.port.onmessage = (event) => {
          if (event.data.type === 'request_data') {
            audioSystem.dspWorker.postMessage({ type: 'request_data' });
          }
        };

        workletNode.connect(audioSystem.audioContext.destination);

        // Wait for the 'ready' signal from the DSP worker before enabling the UI.
        audioSystem.dspWorker.onmessage = (event) => {
            if (event.data.type === 'ready') {
                console.log("All systems ready.");
                audioSystem.isReady = true;
                statusElement.textContent = 'Ready. Click Start Audio.';
            }
        };
      }

      async function toggleAudio() {
        if (!audioSystem.audioContext) await setupAudio();

        if (!audioSystem.isReady) {
            statusElement.textContent = "Please wait, DSP worker is initializing...";
            return;
        }

        if (audioSystem.audioContext.state === 'running') {
            await audioSystem.audioContext.suspend();
            controlButton.textContent = 'Resume Audio';
        } else {
            await audioSystem.audioContext.resume();
            controlButton.textContent = 'Pause Audio';
        }
      }
      
      controlButton.disabled = true;
    </script>
  </body>
</html>

