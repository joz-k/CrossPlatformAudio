<!doctype html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>C++ Audio (DSP Worker)</title>
    <style>
        body { font-family: sans-serif; text-align: center; }
        #controlButton { font-size: 1.5em; }
    </style>
  </head>
  <body>
    <h1>C++ WebAssembly Audio Engine (With a dedicated DSP Worker)</h1>
    <button id="controlButton">Start Audio</button>
    <div id="status"></div>
    <script src="coi-serviceworker.min.js"></script>

    <!-- This script MUST come BEFORE the main Emscripten script (`{{{ SCRIPT }}}`) -->

    <script type='text/javascript'>
      // Define globals in the top-level scope.
      const controlButton = document.getElementById('controlButton');
      const statusElement = document.getElementById('status');

      // This is the global "struct" to hold all our audio components.
      const audioSystem = {
        audioContext: null,
        dspWorker: null,
        isReady: false
      };

      // The `Module` object is defined synchronously in the global scope.
      // The Emscripten loader script will find this object and use our
      // onRuntimeInitialized callback. This eliminates the race condition.
      var Module = {
        onRuntimeInitialized: function() {
          console.log('Emscripten runtime initialized.');
          Module.callMain(); // Initialize the C++ side.
          
          // Now that C++ is ready, we can enable the UI.
          controlButton.disabled = false;
          controlButton.addEventListener('click', toggleAudio);
          statusElement.textContent = 'WASM Ready. Click Start Audio to initialize audio systems.';
        }
      };

      // This self-executing async function handles the service worker logic.
      // It runs independently of the Module initialization.
      (async () => {
        if (typeof SharedArrayBuffer === 'undefined') {
          statusElement.innerHTML = "SharedArrayBuffer is not available. <br> Activating headers via Service Worker and reloading...";
          controlButton.disabled = true;
          return; // Stop execution; the page will reload.
        }
      })();

      // This function is now the single, atomic setup-and-play entry point.
      async function setupAudio() {
        audioSystem.audioContext = new (window.AudioContext || window.webkitAudioContext)();
        audioSystem.dspWorker = new Worker('dsp-worker.js');
        await audioSystem.audioContext.audioWorklet.addModule('audioworklet-processor.js');

        const buffer_frames = 8192;
        const audio_sab = new SharedArrayBuffer(buffer_frames * 2 * 4);
        const state_sab = new SharedArrayBuffer(2 * 4);

        // Get the real Sample Rate
        const actual_sample_rate = audioSystem.audioContext.sampleRate;
        statusElement.textContent = `AudioContext created at ${actual_sample_rate} Hz. Initializing DSP worker...`;

        // cwrap functions must be called *after* onRuntimeInitialized.
        const cpp_set_sample_rate = Module.cwrap('set_sample_rate', null, ['number']);
        cpp_set_sample_rate(actual_sample_rate);

        audioSystem.dspWorker.postMessage({
            type: 'init',
            wasm_module_name: 'CrossPlatformAudio.js',
            audio_sab: audio_sab,
            state_sab: state_sab
        });

        const workletNode = new AudioWorkletNode(audioSystem.audioContext, 'cpp-audio-processor');
        workletNode.port.postMessage({ audio_sab: audio_sab, state_sab: state_sab });

        const cpp_generate_audio = Module.cwrap('generate_audio_data', 'void', ['number', 'number']);

        workletNode.port.onmessage = (event) => {
          if (event.data.type === 'request_data') {
            // Forward the request to the DSP worker.
            audioSystem.dspWorker.postMessage({ type: 'request_data', cpp_func: cpp_generate_audio });
          }
        };

        workletNode.connect(audioSystem.audioContext.destination);

        audioSystem.dspWorker.onmessage = (event) => {
            if (event.data.type === 'ready') {
                console.log("All systems ready.");
                audioSystem.isReady = true;
                statusElement.textContent = 'Ready. Click Start Audio.';
            }
        };
      }

      async function toggleAudio() {
        if (!audioSystem.audioContext) await setupAudio();

        if (!audioSystem.isReady) {
            statusElement.textContent = "Please wait, DSP worker is initializing...";
            return;
        }
        if (audioSystem.audioContext.state === 'running') {
            await audioSystem.audioContext.suspend();
            controlButton.textContent = 'Resume Audio';
        } else {
            await audioSystem.audioContext.resume();
            controlButton.textContent = 'Pause Audio';
        }
      }

      controlButton.disabled = true;
    </script>

    <!-- The Emscripten loader script runs here. It will find the global Module object defined above. -->
    {{{ SCRIPT }}}

  </body>
</html>

